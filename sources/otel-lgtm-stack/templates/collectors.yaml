---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: {{ .Release.Namespace }}
---    
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - events
      - namespaces
      - namespaces/status
      - nodes
      - nodes/spec
      - nodes/stats
      - nodes/metrics
      - nodes/proxy
      - persistentvolumes
      - persistentvolumeclaims
      - pods
      - pods/status
      - replicationcontrollers
      - replicationcontrollers/status
      - resourcequotas
      - services
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - apiGroups: [""]
    resources:
      - namespaces
    verbs: ["get", "list", "watch"]
  # Added permission for non-resource URLs to access metrics endpoints
  - nonResourceURLs: 
      - "/metrics"
      - "/metrics/cadvisor"
      - "/stats/summary"
      - "/api/v1/nodes/*/proxy/metrics"
      - "/api/v1/nodes/*/proxy/metrics/cadvisor"
    verbs: ["get"]
  # Added networking.k8s.io API group for newer Kubernetes versions
  - apiGroups: ["networking.k8s.io"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  # Added permission to access custom resource definitions if using any
  - apiGroups: ["apiextensions.k8s.io"]
    resources:
      - customresourcedefinitions
    verbs: ["get", "list", "watch"]
  # Added events.k8s.io API group for newer Kubernetes events
  - apiGroups: ["events.k8s.io"]
    resources:
      - events
    verbs: ["get", "list", "watch"]
  - apiGroups: ["monitoring.coreos.com"]
    resources:
    - servicemonitors
    - podmonitors
    - probes
    - scrapeconfigs
    verbs: ["*"]
  - apiGroups: ["apps"]
    resources:
    - daemonsets
    - deployments
    - replicasets
    - statefulset
    verbs: ["get", "list", "watch"]
  - apiGroups: ["autoscaling"]
    resources:
      - horizontalpodautoscalers
    verbs: ["get", "list", "watch"]
  - apiGroups: ["discovery.k8s.io"]
    resources:
    - endpointslices
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
  - kind: ServiceAccount
    name: otel-collector
    namespace: {{ .Release.Namespace }}
---
# Source: openobserve-collector/templates/instrumentation-dotnet.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-dotnet
  namespace: {{ .Release.Namespace }}
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  dotnet:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
---
# Source: openobserve-collector/templates/instrumentation-go.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-go
  namespace: {{ .Release.Namespace }}
spec:
  go:
    # image: ghcr.io/openobserve/opentelemetry-go-instrumentation/autoinstrumentation-go:v0.7.0-alpha-5
    image: ghcr.io/open-telemetry/opentelemetry-go-instrumentation/autoinstrumentation-go:v0.19.0-alpha
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ##
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
---
# Source: openobserve-collector/templates/instrumentation-java.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-java
  namespace: {{ .Release.Namespace }}
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  java:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
---
# Source: openobserve-collector/templates/instrumentation-nodejs.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-nodejs
  namespace: {{ .Release.Namespace }}
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
---
# Source: openobserve-collector/templates/instrumentation-python.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-python
  namespace: {{ .Release.Namespace }}
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  python:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
      - name: OTEL_LOGS_EXPORTER
        value: otlp_proto_http
      - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
        value: "false" # set to true to enable auto instrumentation for logs
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-logs
  namespace: {{ .Release.Namespace }}
spec:
  mode: daemonset
  serviceAccount: otel-collector
  image: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0"
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  tolerations:
        - effect: NoSchedule
          key: exampleKey1
          operator: Equal
          value: "true"
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
  resources:
    limits:
      cpu: {{ .Values.collectors.resources.logs.limits.cpu }}
      memory: {{ .Values.collectors.resources.logs.limits.memory }}
    requests:
      cpu: {{ .Values.collectors.resources.logs.requests.cpu }}
      memory: {{ .Values.collectors.resources.logs.requests.memory }}
  securityContext: ####
    privileged: true
    runAsUser: 0 ####
    runAsGroup: 0 ####
  config: ####
    receivers:
      filelog/std:
        exclude:
        - /var/log/pods/*/otel-collector/*.log
        - /var/log/pods/*/otc-container/*.log
        - /var/log/pods/*/openobserve-ingester/*.log
        include:
        - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          output: extract_metadata_from_filepath
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - id: parser-containerd
          output: extract_metadata_from_filepath
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - id: parser-docker
          output: extract_metadata_from_filepath
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - cache:
            size: 128
          id: extract_metadata_from_filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.log
          to: body
          type: move
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        start_at: end
    processors:
      attributes:
        actions:
          - key: k8s_cluster_name
            action: insert
            value: "cluster-name" ### value should be updated based on cluster
      transform: ### this adds k8s.cluster.name as a label filter
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - set(resource.attributes["k8s.cluster.name"], attributes["k8s.cluster.name"])
              - set(resource.attributes["component.id"], attributes["component.id"])
              - set(resource.attributes["workload.id"], attributes["workload.id"])
      batch:
        send_batch_size: 2000
        timeout: 10s
      k8sattributes:
        auth_type: serviceAccount
        extract:
          labels:
          - from: pod
            key: app.kubernetes.io/name
            tag_name: service.name
          - from: pod
            key: k8s-app
            tag_name: service.name
          - from: pod
            key: app.kubernetes.io/instance
            tag_name: k8s.app.instance
          - from: pod
            key: app.kubernetes.io/version
            tag_name: service.version
          - from: pod
            key: app.kubernetes.io/component
            tag_name: k8s.app.component
          - from: pod
            key: airm.silogen.ai/component-id
            tag_name: component.id
          - from: pod
            key: airm.silogen.ai/workload-id
            tag_name: workload.id
          metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.pod.start_time
          - k8s.deployment.name
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.tag
          - container.image.name
          - k8s.cluster.uid
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
          - from: resource_attribute
            name: k8s.node.name
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
        - sources:
          - from: connection
      resourcedetection:
        detectors:
        - env
        override: true
        timeout: 2s

    extensions: ##
      basicauth/loki-tenant:
        client_auth:
          username: loki_tenant_demo
          password: loki-tenant-demo-password

    exporters:
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true

      # Debug exporter - can remove in production
      debug:
        verbosity: detailed    

    service:
      extensions: [basicauth/loki-tenant]
      pipelines:
        logs:
          receivers: [filelog/std]
          processors: [batch, k8sattributes, attributes, transform]
          exporters: [otlp]
          #exporters: [otlp, debug]
  volumes:
    - name: varlog
      hostPath:
        path: /var/log
        type: ''
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
        type: ''
  volumeMounts:
    - name: varlog
      mountPath: /var/log
    - name: varlibdockercontainers
      readOnly: true
      mountPath: /var/lib/docker/containers
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-logs-events
  namespace: {{ .Release.Namespace }}
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0
  mode: deployment
  serviceAccount: otel-collector
  config: 
    receivers:
      k8sobjects:
        auth_type: serviceAccount
        objects:
          - name: events
            mode: watch
            group: events.k8s.io
            exclude_watch_type: ["MODIFIED", "DELETED", "BOOKMARK"]
            interval: 30s
    processors:
      attributes:
        actions:
          - key: log_type
            action: insert
            value: "k8s_event"

      k8sattributes:
        auth_type: serviceAccount
        extract:
          labels:
          - from: pod
            key: airm.silogen.ai/component-id
            tag_name: component.id
          - from: pod
            key: airm.silogen.ai/workload-id
            tag_name: workload.id
          # Extract annotations that might help identify related resources 
          annotations:
          - from: pod
            key: airm.silogen.ai/workload-id
            tag_name: workload.id.annotation
          metadata: 
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.job.name
          - k8s.job.uid
        passthrough: false
        # For events: the k8sobjects receiver sets k8s.object.kind, k8s.object.name, k8s.namespace.name
        # Pod association will only work for events directly about pods
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name

      # Filter processor to drop events with empty notes
      filter/non-empty-note:
        error_mode: ignore
        logs:
          log_record:
            - '(body["object"]["note"] != nil and body["object"]["note"] != "") or (body["object"]["message"] != nil and body["object"]["message"] != "")'

      # Transform processor to extract Pod information from events for k8sattributes matching
      transform/extract-pod-info:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              # For v1 events (involvedObject field)
              # Extract pod UID from involvedObject for k8sattributes processor matching
              - set(resource.attributes["k8s.pod.uid"], body["object"]["involvedObject"]["uid"]) where body["object"]["involvedObject"]["kind"] == "Pod"
              - set(resource.attributes["k8s.pod.name"], body["object"]["involvedObject"]["name"]) where body["object"]["involvedObject"]["kind"] == "Pod"
              - set(resource.attributes["k8s.namespace.name"], body["object"]["involvedObject"]["namespace"]) where body["object"]["involvedObject"]["kind"] == "Pod"
              
              # For events.k8s.io/v1 events (regarding field)
              - set(resource.attributes["k8s.pod.uid"], body["object"]["regarding"]["uid"]) where body["object"]["regarding"]["kind"] == "Pod"
              - set(resource.attributes["k8s.pod.name"], body["object"]["regarding"]["name"]) where body["object"]["regarding"]["kind"] == "Pod"
              - set(resource.attributes["k8s.namespace.name"], body["object"]["regarding"]["namespace"]) where body["object"]["regarding"]["kind"] == "Pod"

      # Transform processor to set final resource attributes
      transform/set-attributes:
        error_mode: ignore
        log_statements:
          - context: log
            statements:
              - set(resource.attributes["log.type"], attributes["log_type"])
              
              # Copy enriched labels from k8sattributes to resource attributes
              - set(resource.attributes["component.id"], attributes["component.id"]) where attributes["component.id"] != nil
              - set(resource.attributes["workload.id"], attributes["workload.id"]) where attributes["workload.id"] != nil
  
              # Replace body with plain text note or message
              - set(body, body["object"]["message"]) where body["object"]["message"] != nil and body["object"]["note"] == nil
              - set(body, body["object"]["note"]) where body["object"]["note"] != nil
    exporters:
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
      debug:
        verbosity: detailed
    service:
      pipelines:
        logs:
          receivers: [k8sobjects]
          processors: [transform/extract-pod-info, k8sattributes, attributes, transform/set-attributes]
          exporters: [otlp, debug]
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-metrics-k8s
  namespace: {{ .Release.Namespace }}
spec:
  mode: deployment
  serviceAccount: otel-collector
  image: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0"
  replicas: 1
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
  resources:
    limits:
      cpu: {{ .Values.collectors.resources.metrics.limits.cpu }}
      memory: {{ .Values.collectors.resources.metrics.limits.memory }}
    requests:
      cpu: {{ .Values.collectors.resources.metrics.requests.cpu }}
      memory: {{ .Values.collectors.resources.metrics.requests.memory }}
  config:
    receivers:
      prometheus:
        config:
          scrape_configs:
            - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              job_name: kubernetes-apiservers
              kubernetes_sd_configs:
              - role: endpoints
              relabel_configs:
              - action: keep
                regex: default;kubernetes;https
                source_labels:
                - __meta_kubernetes_namespace
                - __meta_kubernetes_service_name
                - __meta_kubernetes_endpoint_port_name
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
            - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              job_name: kubernetes-nodes
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - replacement: kubernetes.default.svc:443
                target_label: __address__
              - regex: (.+)
                replacement: /api/v1/nodes/$1/proxy/metrics
                source_labels:
                - __meta_kubernetes_node_name
                target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
            - bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              job_name: kubernetes-nodes-cadvisor
              kubernetes_sd_configs:
              - role: node
              relabel_configs:
              - action: labelmap
                regex: __meta_kubernetes_node_label_(.+)
              - replacement: kubernetes.default.svc:443
                target_label: __address__
              - regex: (.+)
                replacement: /api/v1/nodes/$1/proxy/metrics/cadvisor
                source_labels:
                - __meta_kubernetes_node_name
                target_label: __metrics_path__
              scheme: https
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
            - honor_labels: true
              job_name: kubernetes-service-endpoints
              kubernetes_sd_configs:
              - role: endpoints
              relabel_configs:
              - action: keep
                regex: true
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_scrape
              - action: drop
                regex: true
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
              - action: replace
                regex: (https?)
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_scheme
                target_label: __scheme__
              - action: replace
                regex: (.+)
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_path
                target_label: __metrics_path__
              - action: replace
                regex: (.+?)(?::\d+)?;(\d+)
                replacement: $1:$2
                source_labels:
                - __address__
                - __meta_kubernetes_service_annotation_prometheus_io_port
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - action: replace
                source_labels:
                - __meta_kubernetes_namespace
                target_label: namespace
              - action: replace
                source_labels:
                - __meta_kubernetes_service_name
                target_label: service
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_node_name
                target_label: node
            - honor_labels: true
              job_name: kubernetes-service-endpoints-slow
              kubernetes_sd_configs:
              - role: endpoints
              relabel_configs:
              - action: keep
                regex: true
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_scrape_slow
              - action: replace
                regex: (https?)
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_scheme
                target_label: __scheme__
              - action: replace
                regex: (.+)
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_path
                target_label: __metrics_path__
              - action: replace
                regex: (.+?)(?::\d+)?;(\d+)
                replacement: $1:$2
                source_labels:
                - __address__
                - __meta_kubernetes_service_annotation_prometheus_io_port
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_service_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - action: replace
                source_labels:
                - __meta_kubernetes_namespace
                target_label: namespace
              - action: replace
                source_labels:
                - __meta_kubernetes_service_name
                target_label: service
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_node_name
                target_label: node
              scrape_interval: 5m
              scrape_timeout: 30s
            - honor_labels: true
              job_name: prometheus-pushgateway
              kubernetes_sd_configs:
              - role: service
              relabel_configs:
              - action: keep
                regex: pushgateway
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_probe
            - honor_labels: true
              job_name: kubernetes-services
              kubernetes_sd_configs:
              - role: service
              metrics_path: /probe
              params:
                module:
                - http_2xx
              relabel_configs:
              - action: keep
                regex: true
                source_labels:
                - __meta_kubernetes_service_annotation_prometheus_io_probe
              - source_labels:
                - __address__
                target_label: __param_target
              - replacement: blackbox
                target_label: __address__
              - source_labels:
                - __param_target
                target_label: instance
              - action: labelmap
                regex: __meta_kubernetes_service_label_(.+)
              - source_labels:
                - __meta_kubernetes_namespace
                target_label: namespace
              - source_labels:
                - __meta_kubernetes_service_name
                target_label: service
            - honor_labels: true
              job_name: kubernetes-pods
              kubernetes_sd_configs:
              - role: pod
              relabel_configs:
              - action: keep
                regex: true
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_scrape
              - action: drop
                regex: true
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
              - action: replace
                regex: (https?)
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_scheme
                target_label: __scheme__
              - action: replace
                regex: (.+)
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_path
                target_label: __metrics_path__
              - action: replace
                regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
                replacement: '[$2]:$1'
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_port
                - __meta_kubernetes_pod_ip
                target_label: __address__
              - action: replace
                regex: (\d+);((([0-9]+?)(\.|$)){4})
                replacement: $2:$1
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_port
                - __meta_kubernetes_pod_ip
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - action: replace
                source_labels:
                - __meta_kubernetes_namespace
                target_label: namespace
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_name
                target_label: pod
              - action: drop
                regex: Pending|Succeeded|Failed|Completed
                source_labels:
                - __meta_kubernetes_pod_phase
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_node_name
                target_label: node
            - honor_labels: true
              job_name: kubernetes-pods-slow
              kubernetes_sd_configs:
              - role: pod
              relabel_configs:
              - action: keep
                regex: true
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_scrape_slow
              - action: replace
                regex: (https?)
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_scheme
                target_label: __scheme__
              - action: replace
                regex: (.+)
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_path
                target_label: __metrics_path__
              - action: replace
                regex: (\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})
                replacement: '[$2]:$1'
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_port
                - __meta_kubernetes_pod_ip
                target_label: __address__
              - action: replace
                regex: (\d+);((([0-9]+?)(\.|$)){4})
                replacement: $2:$1
                source_labels:
                - __meta_kubernetes_pod_annotation_prometheus_io_port
                - __meta_kubernetes_pod_ip
                target_label: __address__
              - action: labelmap
                regex: __meta_kubernetes_pod_annotation_prometheus_io_param_(.+)
                replacement: __param_$1
              - action: labelmap
                regex: __meta_kubernetes_pod_label_(.+)
              - action: replace
                source_labels:
                - __meta_kubernetes_namespace
                target_label: namespace
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_name
                target_label: pod
              - action: drop
                regex: Pending|Succeeded|Failed|Completed
                source_labels:
                - __meta_kubernetes_pod_phase
              - action: replace
                source_labels:
                - __meta_kubernetes_pod_node_name
                target_label: node
              scrape_interval: 5m
              scrape_timeout: 30s
    processors:
      batch:
        send_batch_size: 2000
          #send_batch_size: 1000  # Reduced from 10000
          #send_batch_max_size: 1000  # Added explicit max size
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      attributes:
        actions:
          - key: k8s_cluster_name
            action: insert
            value: "cluster-name" ### value should be updated based on cluster

    exporters:
      # Configure your actual backend exporters here
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
      debug:
        verbosity: detailed
    
    service:
      pipelines:
        metrics:
          receivers: [prometheus]
          processors: [memory_limiter, batch, attributes]
          exporters: [otlp]
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-metrics-rest
  namespace: {{ .Release.Namespace }}
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0
  mode: deployment
  podAnnotations:
    prometheus.io/port: "8888"
    prometheus.io/scrape: "true"
  replicas: 1
  resources:
    limits:
      cpu: {{ .Values.collectors.resources.metrics.limits.cpu }}
      memory: {{ .Values.collectors.resources.metrics.limits.memory }}
    requests:
      cpu: {{ .Values.collectors.resources.metrics.requests.cpu }}
      memory: {{ .Values.collectors.resources.metrics.requests.memory }}
  serviceAccount: otel-collector
  config:
    exporters:
      debug:
        verbosity: detailed
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
    processors:
      attributes:
        actions:
          - action: insert
            key: k8s_cluster_name
            value: cluster-name
      batch:
        send_batch_size: 2000
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    receivers:
      prometheus:
        config:
          scrape_configs:
            - job_name: otel-collector
              scrape_interval: 30s
              static_configs:
                - targets:
                    - localhost:8888
            - dns_sd_configs:
                - names:
                    - opencost-prometheus-opencost-exporter.monitoring
                  port: 9003
                  type: A
              honor_labels: true
              job_name: opencost
              metrics_path: /metrics
              scheme: http
              scrape_interval: 1m
              scrape_timeout: 10s
            - job_name: gpu-operator-metrics-exporter
              kubernetes_sd_configs:
                - role: node
              metrics_path: /metrics
              relabel_configs:
                - action: keep
                  regex: true
                  source_labels:
                    - __meta_kubernetes_node_label_feature_node_kubernetes_io_amd_gpu
                - regex: (.+)
                  replacement: $1:32500
                  source_labels:
                    - __meta_kubernetes_node_address_InternalIP
                  target_label: __address__
                - source_labels:
                    - __meta_kubernetes_node_name
                  target_label: hostname
            - job_name: minio-cluster-metrics
              metrics_path: /minio/v2/metrics/cluster
              scheme: http
              static_configs:
                - targets:
                    - minio.minio-tenant-default.svc.cluster.local
            - job_name: minio-bucket-metrics
              metrics_path: /minio/v2/metrics/bucket
              scheme: http
              static_configs:
                - targets:
                    - minio.minio-tenant-default.svc.cluster.local
            - job_name: minio-resource-metrics
              metrics_path: /minio/v2/metrics/resource
              scheme: http
              static_configs:
                - targets:
                    - minio.minio-tenant-default.svc.cluster.local
            - job_name: argocd-controller
              metrics_path: /metrics
              scheme: http
              static_configs:
                - targets:
                    - argocd-metrics.argocd.svc.cluster.local:8082
            - job_name: argocd-applicationset
              metrics_path: /metrics
              scheme: http
              static_configs:
                - targets:
                    - argocd-applicationset-controller.argocd.svc.cluster.local:8080
            - job_name: argocd-repo-server
              metrics_path: /metrics
              scheme: http
              static_configs:
                - targets:
                    - argocd-repo-server.argocd.svc.cluster.local:8084
            - job_name: longhorn
              metrics_path: /metrics
              scheme: http
              static_configs:
                - targets:
                    - longhorn-backend.longhorn.svc.cluster.local:9500
    service:
      pipelines:
        metrics:
          exporters:
            - otlp
          processors:
            - memory_limiter
            - batch
            - attributes
          receivers:
            - prometheus

---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-metrics-chrony
  namespace: {{ .Release.Namespace }}
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0
  mode: deployment
  podAnnotations:
    prometheus.io/port: "8888"
    prometheus.io/scrape: "true"
  replicas: 1
  resources:
    limits:
      cpu: {{ .Values.collectors.resources.metrics.limits.cpu }}
      memory: {{ .Values.collectors.resources.metrics.limits.memory }}
    requests:
      cpu: {{ .Values.collectors.resources.metrics.requests.cpu }}
      memory: {{ .Values.collectors.resources.metrics.requests.memory }}
  serviceAccount: otel-collector
  config:
    exporters:
      debug:
        verbosity: detailed
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
    processors:
      attributes:
        actions:
          - action: insert
            key: k8s_cluster_name
            value: cluster-name
      batch:
        send_batch_size: 2000
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    receivers:
      prometheus:
        config:
          scrape_configs:
            - job_name: chrony-exporter
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_pod_label_app]
                  regex: chrony-exporter
                  action: keep
                - source_labels: [__meta_kubernetes_pod_ip]
                  target_label: __address__
                  regex: (.*)
                  replacement: $1:9123
                - source_labels: [__meta_kubernetes_pod_node_name]
                  target_label: k8s_node_name
    service:
      pipelines:
        metrics:
          exporters:
            - otlp
          processors:
            - memory_limiter
            - batch
            - attributes
          receivers:
            - prometheus

---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-metrics-airm
  namespace: {{ .Release.Namespace }}
spec:
  image: ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0
  mode: deployment
  podAnnotations:
    prometheus.io/port: "8888"
    prometheus.io/scrape: "true"
  replicas: 1
  resources:
    limits:
      cpu: {{ .Values.collectors.resources.metrics.limits.cpu }}
      memory: {{ .Values.collectors.resources.metrics.limits.memory }}
    requests:
      cpu: {{ .Values.collectors.resources.metrics.requests.cpu }}
      memory: {{ .Values.collectors.resources.metrics.requests.memory }}
  serviceAccount: otel-collector
  config:
    exporters:
      debug:
        verbosity: detailed
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
    processors:
      attributes:
        actions:
          - action: insert
            key: k8s_cluster_name
            value: cluster-name
      batch:
        send_batch_size: 2000
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    receivers:
      prometheus:
        config:
          scrape_configs:
            - job_name: airm-custom-metrics
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: pod
              metrics_path: /
              relabel_configs:
                - action: keep
                  source_labels:
                    - __meta_kubernetes_pod_label_app
                  regex: airm-api
                - regex: (.+)
                  replacement: $1:9009
                  source_labels:
                    - __meta_kubernetes_node_address_InternalIP
                  target_label: __address__
                  action: replace
                - source_labels:
                    - __meta_kubernetes_node_name
                  target_label: hostname

    service:
      pipelines:
        metrics:
          exporters:
            - otlp
          processors:
            - memory_limiter
            - batch
            - attributes
          receivers:
            - prometheus
