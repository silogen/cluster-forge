---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: otel-collector
  namespace: otel-lgtm-stack
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: otel-collector
rules:
  - apiGroups: [""]
    resources:
      - configmaps
      - endpoints
      - events
      - namespaces
      - namespaces/status
      - nodes
      - nodes/spec
      - nodes/stats
      - nodes/metrics
      - nodes/proxy
      - persistentvolumes
      - persistentvolumeclaims
      - pods
      - pods/status
      - replicationcontrollers
      - replicationcontrollers/status
      - resourcequotas
      - services
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources:
      - configmaps
    verbs: ["get"]
  - apiGroups: [""]
    resources:
      - namespaces
    verbs: ["get", "list", "watch"]
  # Added permission for non-resource URLs to access metrics endpoints
  - nonResourceURLs: 
      - "/metrics"
      - "/metrics/cadvisor"
      - "/stats/summary"
      - "/api/v1/nodes/*/proxy/metrics"
      - "/api/v1/nodes/*/proxy/metrics/cadvisor"
    verbs: ["get"]
  # Added networking.k8s.io API group for newer Kubernetes versions
  - apiGroups: ["networking.k8s.io"]
    resources:
      - ingresses
    verbs: ["get", "list", "watch"]
  # Added permission to access custom resource definitions if using any
  - apiGroups: ["apiextensions.k8s.io"]
    resources:
      - customresourcedefinitions
    verbs: ["get", "list", "watch"]
  # Added events.k8s.io API group for newer Kubernetes events
  - apiGroups: ["events.k8s.io"]
    resources:
      - events
    verbs: ["get", "list", "watch"]
  - apiGroups: ["monitoring.coreos.com"]
    resources:
    - servicemonitors
    - podmonitors
    - probes
    - scrapeconfigs
    verbs: ["*"]
  - apiGroups: ["apps"]
    resources:
    - daemonsets
    - deployments
    - replicasets
    - statefulset
    verbs: ["get", "list", "watch"]
  - apiGroups: ["autoscaling"]
    resources:
      - horizontalpodautoscalers
    verbs: ["get", "list", "watch"]
  - apiGroups: ["discovery.k8s.io"]
    resources:
    - endpointslices
    verbs: ["get", "list", "watch"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: otel-collector
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: otel-collector
subjects:
  - kind: ServiceAccount
    name: otel-collector
    namespace: otel-lgtm-stack
---
# Source: openobserve-collector/templates/instrumentation-dotnet.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-dotnet
  namespace: otel-lgtm-stack
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  dotnet:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
---
# Source: openobserve-collector/templates/instrumentation-go.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-go
  namespace: otel-lgtm-stack
spec:
  go:
    # image: ghcr.io/openobserve/opentelemetry-go-instrumentation/autoinstrumentation-go:v0.7.0-alpha-5
    image: ghcr.io/open-telemetry/opentelemetry-go-instrumentation/autoinstrumentation-go:v0.19.0-alpha
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ##
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
---
# Source: openobserve-collector/templates/instrumentation-java.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-java
  namespace: otel-lgtm-stack
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  java:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
---
# Source: openobserve-collector/templates/instrumentation-nodejs.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-nodejs
  namespace: otel-lgtm-stack
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
---
# Source: openobserve-collector/templates/instrumentation-python.yaml
apiVersion: opentelemetry.io/v1alpha1
kind: Instrumentation
metadata:
  name: lgtm-python
  namespace: otel-lgtm-stack
spec:
  exporter:
    endpoint: http://lgtm.lgtm-stack.svc.cluster.local:4318 ###
  propagators:
    - tracecontext
    - baggage
  sampler:
    type: parentbased_traceidratio
    argument: "1"
  python:
    env:
      - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
        value: http/protobuf
      - name: OTEL_EXPORTER_OTLP_METRICS_PROTOCOL
        value: http/protobuf
      - name: OTEL_LOGS_EXPORTER
        value: otlp_proto_http
      - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
        value: "false" # set to true to enable auto instrumentation for logs
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-agent
  namespace: otel-lgtm-stack
spec:
  mode: daemonset
  serviceAccount: otel-collector
  image: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0"
  env:
    - name: K8S_NODE_NAME
      valueFrom:
        fieldRef:
          fieldPath: spec.nodeName
  tolerations:
        - effect: NoSchedule
          key: exampleKey1
          operator: Equal
          value: "true"
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
  resources:
    limits:
      cpu: 1
      memory: 2Gi
    requests:
      cpu: 200m
      memory: 400Mi
  securityContext: ####
    privileged: true
    runAsUser: 0 ####
    runAsGroup: 0 ####
  config: ####
    receivers:
      filelog/std:
        exclude:
        - /var/log/pods/*/otel-collector/*.log
        - /var/log/pods/*/otc-container/*.log
        - /var/log/pods/*/openobserve-ingester/*.log
        include:
        - /var/log/pods/*/*/*.log
        include_file_name: false
        include_file_path: true
        operators:
        - id: get-format
          routes:
          - expr: body matches "^\\{"
            output: parser-docker
          - expr: body matches "^[^ Z]+ "
            output: parser-crio
          - expr: body matches "^[^ Z]+Z"
            output: parser-containerd
          type: router
        - id: parser-crio
          output: extract_metadata_from_filepath
          regex: ^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: 2006-01-02T15:04:05.999999999Z07:00
            layout_type: gotime
            parse_from: attributes.time
          type: regex_parser
        - id: parser-containerd
          output: extract_metadata_from_filepath
          regex: ^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: regex_parser
        - id: parser-docker
          output: extract_metadata_from_filepath
          timestamp:
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
            parse_from: attributes.time
          type: json_parser
        - cache:
            size: 128
          id: extract_metadata_from_filepath
          parse_from: attributes["log.file.path"]
          regex: ^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$
          type: regex_parser
        - from: attributes.log
          to: body
          type: move
        - from: attributes.stream
          to: attributes["log.iostream"]
          type: move
        - from: attributes.container_name
          to: resource["k8s.container.name"]
          type: move
        - from: attributes.namespace
          to: resource["k8s.namespace.name"]
          type: move
        - from: attributes.pod_name
          to: resource["k8s.pod.name"]
          type: move
        - from: attributes.restart_count
          to: resource["k8s.container.restart_count"]
          type: move
        - from: attributes.uid
          to: resource["k8s.pod.uid"]
          type: move
        start_at: end
      # Collect host metrics
      hostmetrics:
        collection_interval: 15s
        root_path: /hostfs
        scrapers:
          cpu: {}
          disk: {}
          filesystem:
            exclude_fs_types:
              fs_types:
              - autofs
              - binfmt_misc
              - bpf
              - cgroup2
              - configfs
              - debugfs
              - devpts
              - devtmpfs
              - fusectl
              - hugetlbfs
              - iso9660
              - mqueue
              - nsfs
              - overlay
              - proc
              - procfs
              - pstore
              - rpc_pipefs
              - securityfs
              - selinuxfs
              - squashfs
              - sysfs
              - tracefs
              match_type: strict
            exclude_mount_points:
              match_type: regexp
              mount_points:
              - /dev/.*
              - /proc/.*
              - /sys/.*
              - /run/k3s/containerd/.*
              - /var/lib/docker/.*
              - /var/lib/kubelet/.*
              - /snap/.*
          load: {}
          network: {}
          process: {}
      kubeletstats:
        auth_type: serviceAccount
        collection_interval: 15s
        endpoint: https://${env:K8S_NODE_NAME}:10250
        extra_metadata_labels:
        - container.id
        - k8s.volume.type
        insecure_skip_verify: true
        metric_groups:
        - node
        - pod
        - container
        - volume
        metrics:
          k8s.pod.cpu_limit_utilization:
            enabled: true
          k8s.pod.cpu_request_utilization:
            enabled: true
          k8s.pod.memory_limit_utilization:
            enabled: true
          k8s.pod.memory_request_utilization:
            enabled: true
      # Collect kubelet metrics
      prometheus:
        config:
          scrape_configs:
            - job_name: kubelet
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: node
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                - target_label: __metrics_path__
                  replacement: /metrics/cadvisor
                - action: labelmap
                  regex: __meta_kubernetes_node_label_(.+)
                - source_labels: [__meta_kubernetes_node_name]
                  action: replace
                  target_label: node
            
            # Pod metrics from the same node
            - job_name: kubernetes-pods-node
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: pod
              relabel_configs:
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: replace
                  target_label: node
                # Keep only pods on the same node as this agent
                - source_labels: [__meta_kubernetes_pod_node_name]
                  action: keep
                  regex: ${K8S_NODE_NAME}
                - source_labels: [__meta_kubernetes_pod_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
    
    processors:
      attributes:
        actions:
          - key: k8s_cluster
            action: insert
            value: "cluster1"
      batch:
        send_batch_size: 2000
        timeout: 10s
      k8sattributes:
        auth_type: serviceAccount
        extract:
          labels:
          - from: pod
            key: app.kubernetes.io/name
            tag_name: service.name
          - from: pod
            key: k8s-app
            tag_name: service.name
          - from: pod
            key: app.kubernetes.io/instance
            tag_name: k8s.app.instance
          - from: pod
            key: app.kubernetes.io/version
            tag_name: service.version
          - from: pod
            key: app.kubernetes.io/component
            tag_name: k8s.app.component
          metadata:
          - k8s.namespace.name
          - k8s.pod.name
          - k8s.pod.uid
          - k8s.node.name
          - k8s.pod.start_time
          - k8s.deployment.name
          - k8s.replicaset.name
          - k8s.replicaset.uid
          - k8s.daemonset.name
          - k8s.daemonset.uid
          - k8s.job.name
          - k8s.job.uid
          - k8s.container.name
          - k8s.cronjob.name
          - k8s.statefulset.name
          - k8s.statefulset.uid
          - container.image.tag
          - container.image.name
          - k8s.cluster.uid
        passthrough: false
        pod_association:
        - sources:
          - from: resource_attribute
            name: k8s.pod.uid
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
          - from: resource_attribute
            name: k8s.node.name
        - sources:
          - from: resource_attribute
            name: k8s.pod.ip
        - sources:
          - from: resource_attribute
            name: k8s.pod.name
          - from: resource_attribute
            name: k8s.namespace.name
        - sources:
          - from: connection
      resourcedetection:
        detectors:
        - env
        override: true
        timeout: 2s
    
    exporters:
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
      
      # Debug exporter - can remove in production
      debug:
        verbosity: detailed    

    service:
      pipelines:
        metrics:
          receivers: [kubeletstats, hostmetrics, prometheus]
          processors: [batch, attributes, k8sattributes]
          exporters: [otlp, debug]
        logs:
          receivers: [filelog/std]
          processors: [batch, attributes, k8sattributes, resourcedetection]
          exporters: [otlp, debug]
  volumes:
    - name: hostfs
      hostPath:
        path: /
    - name: varlog
      hostPath:
        path: /var/log
        type: ''
    - name: varlibdockercontainers
      hostPath:
        path: /var/lib/docker/containers
        type: ''
  volumeMounts:
    - name: hostfs
      mountPath: /hostfs
    - name: varlog
      mountPath: /var/log
    - name: varlibdockercontainers
      readOnly: true
      mountPath: /var/lib/docker/containers
---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-gateway
  namespace: otel-lgtm-stack
spec:
  mode: deployment
  serviceAccount: otel-collector
  image: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0"
  replicas: 2 ####
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 500m
      memory: 1Gi
  config:
    receivers:
      # Receive metrics from otel-collector agents
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # Cluster-wide metrics collection
      prometheus:
        config:
          scrape_configs:
            # Scrape the Kubernetes API server
            - job_name: kubernetes-apiservers
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names: ["default"]
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: kubernetes;https
            
            # Scrape kube-state-metrics if deployed
            - job_name: kube-state-metrics
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: service
                  namespaces:
                    names: ["otel-lgtm-stack"] # Updated to your namespace
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name]
                  action: keep
                  regex: kube-state-metrics
            
            # Scrape cluster-level services with Prometheus annotations
            - job_name: kubernetes-services
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: service
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
                - action: labelmap
                  regex: __meta_kubernetes_service_label_(.+)
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: kubernetes_namespace
                - source_labels: [__meta_kubernetes_service_name]
                  action: replace
                  target_label: kubernetes_name
      # Kubernetes events receiver for cluster-wide events (logs)
      k8s_events:
        auth_type: serviceAccount
#      k8sobjects:
#        auth_type: serviceAccount
#        objects:
#        - field_selector: status.phase=Running
#          interval: 15m
#          mode: pull
#          name: pods
#        - group: events.k8s.io
#          mode: watch
#          name: events    
      k8s_cluster: 
        auth_type: serviceAccount
        collection_interval: 30s  
    
    processors:
      batch:
        send_batch_size: 2000
          #send_batch_size: 1000  # Reduced from 10000
          #send_batch_max_size: 1000  # Added explicit max size
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
          - key: service.name
            value: "k8s-cluster"
            action: upsert
      # Filter to focus on cluster-level logs
      filter/cluster_logs:
        logs:
          include:
            match_type: regexp
            resource_attributes:
              - key: k8s.namespace.name
                value: "kube-system"  # Focus on system namespaces
    
    exporters:
      # Configure your actual backend exporters here
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
      
#      # Prometheus remote write example (if using Prometheus/Mimir/Thanos)
#      prometheusremotewrite:
#        endpoint: "http://prometheus-server/api/v1/write"
#        tls:
#          insecure: true
      
      # Debug exporter - can remove in production
      debug:
        verbosity: detailed
    
    service:
      pipelines:
        metrics:
          receivers: [otlp, prometheus, k8s_cluster]
          processors: [memory_limiter, batch]
          exporters: [otlp, debug]
        logs:
          receivers: [otlp, k8s_events]
          processors: [memory_limiter, batch, resource, filter/cluster_logs]
          exporters: [otlp, debug]
