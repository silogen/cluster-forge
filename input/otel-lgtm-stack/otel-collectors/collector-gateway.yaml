---
apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: otel-collector-gateway
  namespace: otel-lgtm-stack
spec:
  mode: deployment
  serviceAccount: otel-collector
  image: "ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.113.0"
  replicas: 2 ####
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "8888"
  resources:
    limits:
      cpu: 2
      memory: 4Gi
    requests:
      cpu: 500m
      memory: 1Gi
  config:
    receivers:
      # Receive metrics from otel-collector agents
      otlp:
        protocols:
          grpc:
            endpoint: 0.0.0.0:4317
          http:
            endpoint: 0.0.0.0:4318
      
      # Cluster-wide metrics collection
      prometheus:
        config:
          scrape_configs:
            # Scrape the Kubernetes API server
            - job_name: kubernetes-apiservers
              scrape_interval: 30s
              scheme: https
              kubernetes_sd_configs:
                - role: endpoints
                  namespaces:
                    names: ["default"]
              bearer_token_file: /var/run/secrets/kubernetes.io/serviceaccount/token
              tls_config:
                ca_file: /var/run/secrets/kubernetes.io/serviceaccount/ca.crt
                insecure_skip_verify: true
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name, __meta_kubernetes_endpoint_port_name]
                  action: keep
                  regex: kubernetes;https
            
            # Scrape kube-state-metrics if deployed
            - job_name: kube-state-metrics
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: service
                  namespaces:
                    names: ["otel-lgtm-stack"] # Updated to your namespace
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_name]
                  action: keep
                  regex: kube-state-metrics
            
            # Scrape cluster-level services with Prometheus annotations
            - job_name: kubernetes-services
              scrape_interval: 30s
              kubernetes_sd_configs:
                - role: service
              relabel_configs:
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_scrape]
                  action: keep
                  regex: true
                - source_labels: [__meta_kubernetes_service_annotation_prometheus_io_path]
                  action: replace
                  target_label: __metrics_path__
                  regex: (.+)
                - source_labels: [__address__, __meta_kubernetes_service_annotation_prometheus_io_port]
                  action: replace
                  regex: ([^:]+)(?::\d+)?;(\d+)
                  replacement: $1:$2
                  target_label: __address__
                - action: labelmap
                  regex: __meta_kubernetes_service_label_(.+)
                - source_labels: [__meta_kubernetes_namespace]
                  action: replace
                  target_label: kubernetes_namespace
                - source_labels: [__meta_kubernetes_service_name]
                  action: replace
                  target_label: kubernetes_name
      # Kubernetes events receiver for cluster-wide events (logs)
      k8s_events:
        auth_type: serviceAccount
#      k8sobjects:
#        auth_type: serviceAccount
#        objects:
#        - field_selector: status.phase=Running
#          interval: 15m
#          mode: pull
#          name: pods
#        - group: events.k8s.io
#          mode: watch
#          name: events    
      k8s_cluster: 
        auth_type: serviceAccount
        collection_interval: 30s  
    
    processors:
      batch:
        send_batch_size: 2000
          #send_batch_size: 1000  # Reduced from 10000
          #send_batch_max_size: 1000  # Added explicit max size
        timeout: 10s
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
      resource:
        attributes:
          - key: service.name
            value: "k8s-cluster"
            action: upsert
      # Filter to focus on cluster-level logs
      filter/cluster_logs:
        logs:
          include:
            match_type: regexp
            resource_attributes:
              - key: k8s.namespace.name
                value: "kube-system"  # Focus on system namespaces
    
    exporters:
      # Configure your actual backend exporters here
      otlp:
        endpoint: http://lgtm-stack.otel-lgtm-stack.svc.cluster.local:4317
        tls:
          insecure: true
      
#      # Prometheus remote write example (if using Prometheus/Mimir/Thanos)
#      prometheusremotewrite:
#        endpoint: "http://prometheus-server/api/v1/write"
#        tls:
#          insecure: true
      
      # Debug exporter - can remove in production
      debug:
        verbosity: detailed
    
    service:
      pipelines:
        metrics:
          receivers: [otlp, prometheus, k8s_cluster]
          processors: [memory_limiter, batch]
          exporters: [otlp, debug]
        logs:
          receivers: [otlp, k8s_events]
          processors: [memory_limiter, batch, resource, filter/cluster_logs]
          exporters: [otlp, debug]
